{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "859c7b1e",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Problem\n",
    "\n",
    "**In this exercise you will use the Portuguese sea battles data that contains outcomes of naval battles between Portuguese and Dutch/British ships between 1583 and 1663. The dataset has following features:**\n",
    "\n",
    "**_Battle_: Name of the battle place**\n",
    "\n",
    "**_Year_: Year of the battle**\n",
    "\n",
    "**_Portuguese ships_: Number of Portuguese ships**\n",
    "\n",
    "**_Dutch ships_: Number of Dutch ships**\n",
    "\n",
    "**_English ships_: Number of ships from English side**\n",
    "\n",
    "**_Ratio of Portuguese to Dutch/British ships_**\n",
    "\n",
    "**_Spanish Involvement_: $1 = \\text{Yes}$, $0 = \\text{No}$**\n",
    "\n",
    "**_Portuguese outcome_: $-1 = \\text{Defeat}$, $0 = \\text{Draw}$, $1 = \\text{Victory}$**\n",
    "\n",
    "**Use an SVM based model to predict the Portuguese outcome of the battle from the number of ships involved in all sides and Spanish involvement. Try solving the same problem using two other classifiers that you know. Report and compare their results with those from SVM.**\n",
    "\n",
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40554224",
   "metadata": {},
   "source": [
    "_First we need to import any packages including `pandas`, `numpy`, `pyplot`, `StratifiedKFold`, `svm`, `cross_validate`, `tree`, `GaussianNB`, and `confusion_matrix`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6c4687f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08942c7",
   "metadata": {},
   "source": [
    "_Now we can load in the Portuguese sea battles data (`armada`)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "408e7885",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_armada = pd.read_excel('armada.xls', engine = 'xlrd')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a172c488",
   "metadata": {},
   "source": [
    "_Then we can assign the number of ships involved in all sides (`Prtgship`, `Dtchship`, and `Englship`) and Spanish involvement (`Spanish`) as our features and the Portuguese outcome of a battle (`Result`) as our label._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d046ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_armada.drop('Battle', axis = 1).drop('Year', axis = 1).drop('Pratio', axis = 1).drop('Result', axis = 1)\n",
    "label = df_armada['Result']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43559044",
   "metadata": {},
   "source": [
    "_Now, we can split our data into testing and training portions using k-fold stratified cross-validation with 5 randomly split \"chunks\"._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb43c8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 0  1  2  3  4  7  8  9 11 12 13 14 15 16 17 18 19 21 22 24 25 27] TEST: [ 5  6 10 20 23 26]\n",
      "TRAIN: [ 0  3  4  5  6  7  8  9 10 11 12 13 14 15 16 18 19 20 22 23 24 26] TEST: [ 1  2 17 21 25 27]\n",
      "TRAIN: [ 0  1  2  5  6  8  9 10 11 12 13 15 16 17 18 20 21 22 23 25 26 27] TEST: [ 3  4  7 14 19 24]\n",
      "TRAIN: [ 1  2  3  4  5  6  7  9 10 11 12 14 15 17 18 19 20 21 23 24 25 26 27] TEST: [ 0  8 13 16 22]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8 10 13 14 16 17 19 20 21 22 23 24 25 26 27] TEST: [ 9 11 12 15 18]\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits = 5, shuffle = True)\n",
    "\n",
    "for train_index, test_index in skf.split(features, label):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = features.iloc[train_index], features.iloc[test_index]\n",
    "    y_train, y_test = label.iloc[train_index], label.iloc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d9d8c5",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "#### SVM\n",
    "\n",
    "_First we will predict the Portuguese outcome of a battle using an SVM model._\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bfad8a",
   "metadata": {},
   "source": [
    "_To do this, we first load in the SVM classifier._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65e03013",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = svm.SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0580a6",
   "metadata": {},
   "source": [
    "_Then we can fit the SVM classifier to our training data to build our model._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25b8ebda",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = svm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64df5d4",
   "metadata": {},
   "source": [
    "_Now we can use this model to predict the Portuguese outcome of a battle from our test features (`X_test`)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cae23da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = svm_model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd64d29",
   "metadata": {},
   "source": [
    "_We can also measure the test accuracy using our test features (`X_test`) and test label (`y_test`)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95ab985f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229b5b18",
   "metadata": {},
   "source": [
    "_Since this accuracy is fairly low, we can also look at the confusion matrix._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54c35663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 0],\n",
       "       [0, 2, 0],\n",
       "       [0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f778807",
   "metadata": {},
   "source": [
    "_After running the model above mulitple times, this confusion matrix seems to generally stay consistant, meaning that the model mostly predicts the result to be 0 (indicating a draw of a battle). We can further inspect this by checking how large our dataset it and whether the data has balanced classes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "781661f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_armada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5273178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    13\n",
       "-1    10\n",
       " 1     5\n",
       "Name: Result, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_armada['Result'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef627616",
   "metadata": {},
   "source": [
    "_The two outputs above indicate that we are working with a very small dataset (which typically is not ideal) and that the classes are generally not balanced (which could be caused by the dataset being so small). In practice we would likely need substantially more data to get better results, though for the purposes of this exercise we can continue with the data we have._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77eeb29",
   "metadata": {},
   "source": [
    "_So, to continue, it would perhaps be better to get an average accuracy of many iterations. So, we can build a function to do this._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdca745c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for finding the average accuracy of SVM models\n",
    "# n          ->   number of iterations\n",
    "# features   ->   the features for the model to use\n",
    "# label      ->   the label for the model to use\n",
    "def get_avg_svm_accuracy(n, features, label):\n",
    "    \n",
    "    # Set the total training and testing accuracy to be 0\n",
    "    train_tot_acc = 0\n",
    "    test_tot_acc = 0\n",
    "    \n",
    "    # Set the placeholders for minimum and maximum accuracies\n",
    "    min_train_score = 2\n",
    "    max_train_score = -1\n",
    "    min_test_score = 2\n",
    "    max_test_score = -1\n",
    "    \n",
    "    # Iterate through process n number of times\n",
    "    for i in range(0, n):\n",
    "        \n",
    "        # Set up k-fold cross-validation to split the data randomly into 5 \"chunks\"\n",
    "        skf = StratifiedKFold(n_splits = 5, shuffle = True)\n",
    "\n",
    "        # Measure the accuracy of the model in the iteration\n",
    "        cross_val = cross_validate(svm_clf, features, label, cv = skf, return_train_score = True)\n",
    "        \n",
    "        # Find the accuracy scores in the iteration\n",
    "        train_scores = cross_val['train_score']\n",
    "        test_scores = cross_val['test_score']\n",
    "        \n",
    "        # Find the average accuracy scores in the iteration\n",
    "        train_acc = np.mean(train_scores)\n",
    "        test_acc = np.mean(test_scores)\n",
    "        \n",
    "        # Add the average accuracy score in the iteration to the total accuracy score\n",
    "        train_tot_acc = train_tot_acc + train_acc\n",
    "        test_tot_acc = test_tot_acc + test_acc\n",
    "    \n",
    "    # Find the average accuracy of all the iterations\n",
    "    train_avg_acc = (train_tot_acc / n)\n",
    "    test_avg_acc = (test_tot_acc / n)\n",
    "    \n",
    "    # Add the variables to a dictionary\n",
    "    data = {'Train Average Accuracy' : train_avg_acc, 'Test Average Accuracy' : test_avg_acc}\n",
    "    \n",
    "    # Turn the `data` dictionary into a dataframe\n",
    "    df_svm_metrics = pd.DataFrame([data])\n",
    "    \n",
    "    # Return the dataframe\n",
    "    return(df_svm_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5be27b2",
   "metadata": {},
   "source": [
    "_Now we can use this function to get the average accuracy of the SVM models over the course of 200 iterations._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb934f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Average Accuracy</th>\n",
       "      <th>Test Average Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.571923</td>\n",
       "      <td>0.446267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train Average Accuracy  Test Average Accuracy\n",
       "0                0.571923               0.446267"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_avg_svm_accuracy(200, features, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe069348",
   "metadata": {},
   "source": [
    "_From this we see that neither the training or testing accuracy is very high, though now we can compare this performance to other types of classifiers._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc805962",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "#### Decision Trees\n",
    "\n",
    "_Next we can predict the Portuguese outcome of a battle using decision trees._\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485e5b1f",
   "metadata": {},
   "source": [
    "_Again, it is better to look at the average accuracy over many iterations. But first, we need to determine what maximum depth should be used for the desicion trees. So, we can build a funtion that takes in features and a label as parameters and plots how the accuracies vary based on the maximum depth._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01d682d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for ploting the accuracy scores of decision trees at different maximum tree depths\n",
    "# features   ->   the features for the model to use\n",
    "# label      ->   the label for the model to use\n",
    "def plot_dt_max_depth_acc(features, label):\n",
    "    \n",
    "    # Create lists to track the maximum depths and respective accuracies of the test and train data\n",
    "    max_depth = []\n",
    "    train_max_depth_acc = []\n",
    "    test_max_depth_acc = []\n",
    "    \n",
    "    # Iterate through the maximum depth from 1 to 10\n",
    "    for i in range (1, 11):\n",
    "        \n",
    "        # Add the current maximum depth to the `max_depth` list\n",
    "        max_depth.append(i)\n",
    "        \n",
    "        # Build the DecisionTreeClassifier model and set the max_depth to the given value of i in the iteration and\n",
    "        # indicate to choose parameters based on the largest expected “information gain” (impurity/entropy)\n",
    "        d_tree = tree.DecisionTreeClassifier(max_depth = i, criterion = \"entropy\")\n",
    "        \n",
    "        # Measure the accuracy of the model\n",
    "        cross_val = cross_validate(d_tree, features, label, cv = 5, return_train_score = True)\n",
    "        \n",
    "        # Find the accuracy scores given the indicated maximum depth\n",
    "        train_scores = cross_val['train_score']\n",
    "        test_scores = cross_val['test_score']\n",
    "    \n",
    "        # Find the average accuracy scores given the indicated maximum depth and add them to their respective lists\n",
    "        train_max_depth_acc.append(np.mean(train_scores))\n",
    "        test_max_depth_acc.append(np.mean(test_scores))\n",
    "    \n",
    "    # Add the lists to a dictionary\n",
    "    data = {'max_depth' : max_depth,\n",
    "            'train_max_depth_acc' : train_max_depth_acc,\n",
    "            'test_max_depth_acc' : test_max_depth_acc}\n",
    "    \n",
    "    # Turn the `data` dictionary into a dataframe\n",
    "    df_max_depth_acc = pd.DataFrame(data)\n",
    "    \n",
    "    # Plot the dataframe\n",
    "    plt.plot(max_depth, train_max_depth_acc, color = 'red', marker = 'o')\n",
    "    plt.plot(max_depth, test_max_depth_acc, color = 'blue', marker = 'o')\n",
    "    plt.grid(True)\n",
    "    plt.title('Decision Tree Depth Accuracies')\n",
    "    plt.xlabel('Maximum Decision Tree Depth')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc4e3d5",
   "metadata": {},
   "source": [
    "_Now we can apply this function to determine the decision tree depth._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ee26c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_dt_max_depth_acc(features, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a14a993",
   "metadata": {},
   "source": [
    "_From this plot we can see that the accuracy diverges when the maximum decision tree depth is 3, meaning that this is a good value to use as the maximum decision tree depth. Hence, we can assign this to a variable to use going forward._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2064950c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_max_depth = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acdab77",
   "metadata": {},
   "source": [
    "_Now, we can build a similar function as in the case of the SVM model that finds the average accuracy of the decision tree models over many iterations._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "019faa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for finding the average accuracy of decision trees\n",
    "# max_depth  ->   maximum decision tree depth\n",
    "# n          ->   number of iterations\n",
    "# features   ->   the features for the model to use\n",
    "# label      ->   the label for the model to use\n",
    "def get_avg_dt_accuracy(max_depth, n, features, label):\n",
    "\n",
    "    # Build the DecisionTreeClassifier model and set the max_depth to the given parameter (max_depth) and indicate\n",
    "    # to choose parameters based on the largest expected “information gain” (impurity/entropy)\n",
    "    d_tree = tree.DecisionTreeClassifier(max_depth = max_depth, criterion = \"entropy\")\n",
    "    \n",
    "    # Set the total training and testing accuracy to be 0\n",
    "    train_tot_acc = 0\n",
    "    test_tot_acc = 0\n",
    "    \n",
    "    # Set the placeholders for minimum and maximum accuracies\n",
    "    min_train_score = 2\n",
    "    max_train_score = -1\n",
    "    min_test_score = 2\n",
    "    max_test_score = -1\n",
    "    \n",
    "    # Iterate through process n number of times\n",
    "    for i in range(0, n):\n",
    "        \n",
    "        # Set up stratified k-fold cross-validation to split the data randomly into 5 \"chunks\"\n",
    "        skf = StratifiedKFold(n_splits = 5, shuffle = True)\n",
    "\n",
    "        # Measure the accuracy of the model in the iteration\n",
    "        cross_val = cross_validate(d_tree, features, label, cv = skf, return_train_score = True)\n",
    "        \n",
    "        # Find the accuracy scores in the iteration\n",
    "        train_scores = cross_val['train_score']\n",
    "        test_scores = cross_val['test_score']\n",
    "        \n",
    "        # Find the average accuracy scores in the iteration\n",
    "        train_acc = np.mean(train_scores)\n",
    "        test_acc = np.mean(test_scores)\n",
    "        \n",
    "        # Add the average accuracy score in the iteration to the total accuracy score\n",
    "        train_tot_acc = train_tot_acc + train_acc\n",
    "        test_tot_acc = test_tot_acc + test_acc\n",
    "    \n",
    "    # Find the average accuracy of all the iterations\n",
    "    train_avg_acc = (train_tot_acc/n)\n",
    "    test_avg_acc = (test_tot_acc/n)\n",
    "    \n",
    "    # Add the variables to a dictionary\n",
    "    data = {'Train Average Accuracy' : train_avg_acc, 'Test Average Accuracy' : test_avg_acc}\n",
    "    \n",
    "    # Turn the `data` dictionary into a dataframe\n",
    "    df_dt_metrics = pd.DataFrame([data])\n",
    "    \n",
    "    # Return the dataframe\n",
    "    return(df_dt_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a52450",
   "metadata": {},
   "source": [
    "_Now we can use this function to get the average accuracy of the decision tree models over the course of 200 iterations._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1a5408d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Average Accuracy</th>\n",
       "      <th>Test Average Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.713308</td>\n",
       "      <td>0.400533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train Average Accuracy  Test Average Accuracy\n",
       "0                0.713308               0.400533"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_avg_dt_accuracy(dt_max_depth, 200, features, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75dae0c",
   "metadata": {},
   "source": [
    "_Comparing this to the SVM models, we can see that the decision tree models have a higher average training accuracy though a slightly lower average testing accuracy._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d2669c",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "#### Naive Bayes\n",
    "\n",
    "_Lastly we can predict the Portuguese outcome of a battle using Naive Bayes._\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1320bb8",
   "metadata": {},
   "source": [
    "_Same as with the first two types of models, it is better to look at the average accuracy over many iterations. So, we can build a similar function that finds the average accuracy of the Naive Bayes models over many iterations._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71bd54c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for finding the average accuracy of Naive Bayes models\n",
    "# n          ->   number of iterations\n",
    "# features   ->   the features for the model to use\n",
    "# label      ->   the label for the model to use\n",
    "def get_avg_nb_accuracy(n, features, label):\n",
    "\n",
    "    # Load in Naive Bayes classifier    \n",
    "    nb_clf = GaussianNB()\n",
    "    \n",
    "    # Set the total training and testing accuracy to be 0\n",
    "    train_tot_acc = 0\n",
    "    test_tot_acc = 0\n",
    "    \n",
    "    # Set the placeholders for minimum and maximum accuracies\n",
    "    min_train_score = 2\n",
    "    max_train_score = -1\n",
    "    min_test_score = 2\n",
    "    max_test_score = -1\n",
    "    \n",
    "    # Iterate through process n number of times\n",
    "    for i in range(0, n):\n",
    "        \n",
    "        # Set up stratified k-fold cross-validation to split the data randomly into 5 \"chunks\"\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "\n",
    "        # Measure the accuracy of the model in the iteration\n",
    "        cross_val = cross_validate(nb_clf, features, label, cv = skf, return_train_score = True)\n",
    "        \n",
    "        # Find the accuracy scores in the iteration\n",
    "        train_scores = cross_val['train_score']\n",
    "        test_scores = cross_val['test_score']\n",
    "        \n",
    "        # Find the average accuracy scores in the iteration\n",
    "        train_acc = np.mean(train_scores)\n",
    "        test_acc = np.mean(test_scores)\n",
    "        \n",
    "        # Add the average accuracy score in the iteration to the total accuracy score\n",
    "        train_tot_acc = train_tot_acc + train_acc\n",
    "        test_tot_acc = test_tot_acc + test_acc\n",
    "    \n",
    "    # Find the average accuracy of all the iterations\n",
    "    train_avg_acc = (train_tot_acc/n)\n",
    "    test_avg_acc = (test_tot_acc/n)\n",
    "    \n",
    "    # Add the variables to a dictionary\n",
    "    data = {'Train Average Accuracy' : train_avg_acc, 'Test Average Accuracy' : test_avg_acc}\n",
    "    \n",
    "    # Turn the `data` dictionary into a dataframe\n",
    "    df_nb_metrics = pd.DataFrame([data])\n",
    "    \n",
    "    # Return the dataframe\n",
    "    return(df_nb_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af8f233",
   "metadata": {},
   "source": [
    "_Now we can use this function to get the average accuracy of the Naive Bayes models over the course of 200 iterations._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cdcadb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Average Accuracy</th>\n",
       "      <th>Test Average Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.414506</td>\n",
       "      <td>0.322867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train Average Accuracy  Test Average Accuracy\n",
       "0                0.414506               0.322867"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_avg_nb_accuracy(200, features, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accbebcb",
   "metadata": {},
   "source": [
    "_Comparing this to the SVM models, we can see that the Naive Bayes models have both a lower average training and testing accuracy._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f886efc",
   "metadata": {},
   "source": [
    "##### _Conclusion:_\n",
    "\n",
    "_In summary, none of the classifier models performed very well. Comparatively, the SVM models did perform better than the decision tree models and the Naive Bayes models, though none of the models produced acceptable accuracy scores. However, as noted previously, it is typically not ideal to be working with such a small dataset, which is likely why none of our models performed very well. In practice, we would have access to more data to train our models on which would likely improve model performance._"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
